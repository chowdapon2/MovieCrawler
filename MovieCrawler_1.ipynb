{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin_Chiou\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\selenium\\webdriver\\phantomjs\\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年最新电影_第1页-BT电影天堂\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url_list = \"http://www.btbtdy.com/screen/1--2018---time-1.html\"\n",
    "\n",
    "driver = webdriver.PhantomJS('D:\\\\Github\\\\MovieCrawler\\\\phantomjs.exe')\n",
    "# get()方法會一直等到頁面被完全加載，然後才會繼續程序\n",
    "driver.get(url_list)\n",
    "\n",
    "# 把selenium的webdriver调用page_source函数在传入BeautifulSoup中，就可以用BeautifulSoup解析网页了\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "#print (soup.prettify())\n",
    "# p_list = soup.find_all('p', class_='title')\n",
    "\n",
    "# for p in p_list:\n",
    "#     print(p.contents[0].text)\n",
    "\n",
    "\n",
    "# a_list = soup.find_all('a', target='_blank')\n",
    "# for a in a_list:\n",
    "#     print(a)\n",
    "#     print(\"a.content is %s\" % (a.contents))  \n",
    "\n",
    "# a_list = soup.find_all('a', target='_blank')\n",
    "# for a in a_list:\n",
    "#     print(a)\n",
    "#     print(\"a.content is %s\" % (a.contents))  \n",
    "\n",
    "\n",
    "\n",
    "# 打印獲取的文本內容\n",
    "#print(data)\n",
    "\n",
    "# 打印頁面標題：XXXX年最新电影_第1页-BT电影天堂\n",
    "print(driver.title)\n",
    "\n",
    "p_list = soup.find_all('p', class_='title')\n",
    "f = open('MovieNames.txt', 'w', encoding = 'UTF-8')    # 也可使用指定路徑等方式，如： C:\\A.txt\n",
    "for p in p_list:\n",
    "    f.write(p.contents[0].text + '\\n')\n",
    "\n",
    "f.close()    \n",
    "    \n",
    "driver.quit()\n",
    "\n",
    "# http://www.btbtdy.com/ herf=btdy/dy11737.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取txt檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['朝鲜名侦探：吸血怪魔的秘密', '潜伏4：锁命亡灵', '古墓丽影：源起之战', '绝代天后黛莉达', '捷德奥特曼 剧场版：连接吧！心愿！！', '窥镜']\n"
     ]
    }
   ],
   "source": [
    "movieNameList=[]\n",
    "f = open(\"D:\\\\Github\\\\MovieCrawler\\\\MovieNames.txt\",\"r\", encoding = 'UTF-8')\n",
    "for line in f:\n",
    "    #print(line[:-1])\n",
    "    movieNameList.append(line[:-1])\n",
    "#In [13]:l = list(range(10))\n",
    "#In [13]: l\n",
    "#Out[13]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "#In [16]: l[:-1]\n",
    "#Out[16]: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "f.close() \n",
    "# for i in movieNameList:\n",
    "#     print(i)\n",
    "print (movieNameList[0:6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬Imdb頁面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin_Chiou\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\selenium\\webdriver\\phantomjs\\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"ratingValue\">\n",
      "<strong title=\"7.0 based on 100 user ratings\"><span itemprop=\"ratingValue\">7.0</span></strong><span class=\"grey\">/</span><span class=\"grey\" itemprop=\"bestRating\">10</span> </div>]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url_list = \"http://www.imdb.com/title/tt5556068/\"\n",
    "\n",
    "driver = webdriver.PhantomJS('D:\\\\Github\\\\MovieCrawler\\\\phantomjs.exe')\n",
    "driver.get(url_list)\n",
    "\n",
    "# 把selenium的webdriver调用page_source函数在传入BeautifulSoup中，就可以用BeautifulSoup解析网页了\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "d_list = soup.find_all('div', class_='ratingValue')\n",
    "\n",
    "print(d_list)\n",
    "# for d in d_list:\n",
    "#     print(d.descendants)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 實際測試\n",
    "#### 為了不要一直import , 先import一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c57d9b6e349f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing import Pool\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "totalList = []\n",
    "\n",
    "def getDobanAndImdbRating(movieName):\n",
    "    doubanUrl_list = \"https://movie.douban.com/\"\n",
    "    driver = webdriver.PhantomJS('D:\\\\Github\\\\MovieCrawler\\\\phantomjs.exe')\n",
    "    driver.get(doubanUrl_list)\n",
    "    outputList=[]\n",
    "    \n",
    "    # 把selenium的webdriver调用page_source函数在传入BeautifulSoup中，就可以用BeautifulSoup解析网页了\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    #找豆瓣電影的search bar\n",
    "    inputSearch = driver.find_element_by_name(\"search_text\")\n",
    "    ChineseMovieName = movieName\n",
    "    inputSearch.send_keys(ChineseMovieName)\n",
    "    inputSearch.submit()\n",
    "    #time.sleep(2)\n",
    "\n",
    "    #印出找到的電影名稱跟豆瓣評分\n",
    "    searchOutput = driver.find_element_by_class_name(\"title\")\n",
    "    outputList.append(ChineseMovieName)\n",
    "    searchHerf = searchOutput.find_element_by_css_selector('a').get_attribute('href')\n",
    "    outputList.append(searchHerf)\n",
    "    rating_num = driver.find_element_by_class_name(\"rating_nums\")\n",
    "    outputList.append(\"豆瓣 : \"+rating_num.text)\n",
    "    \n",
    "    #點進去該電影後找Imdb的連結\n",
    "    driver.get(searchHerf)\n",
    "    # get()方法會一直等到頁面被完全加載，然後才會繼續程序, 所以不需要sleep等待\n",
    "    html = driver.page_source\n",
    "    try:\n",
    "        IMDBLink = driver.find_element_by_partial_link_text(\"tt\").get_attribute('href')\n",
    "    except:\n",
    "        print (\"There is no IMDB!\")\n",
    "        outputList.append(\"沒有Imdb 連結\")\n",
    "        return outputList\n",
    "    outputList.append(\"Imdb 連結: \" +IMDBLink)\n",
    "    driver.get(IMDBLink)\n",
    "    #html = driver.page_source\n",
    "    #soup = BeautifulSoup(html, \"html.parser\")\n",
    "    try:\n",
    "        ImdbRating = driver.find_element_by_class_name(\"ratingValue\")\n",
    "    except:\n",
    "        print (\"There is no IMDB rating!\")\n",
    "        outputList.append(\"沒有Imdb rating\")\n",
    "        return outputList\n",
    "    outputList.append(\"IMDB : \" +ImdbRating.text)\n",
    "    imdbMovieName = driver.find_element_by_xpath(\"//*[@id='title-overview-widget']//h1\")\n",
    "    outputList.append(imdbMovieName.text)\n",
    "    \n",
    "    return outputList\n",
    "\n",
    "# for i in movieNameList:\n",
    "#     totalList.append(getDobanAndImdbRating(i))\n",
    "#     print(totalList)\n",
    "#     print(\"==============================================================================\")\n",
    "totalList.append(getDobanAndImdbRating(movieNameList[5]))\n",
    "print(totalList)\n",
    "\n",
    "# p = Pool(4) # 设置进程池大小\n",
    "# for i in movieNameList[0:4]:\n",
    "#     p.apply_async(getDobanAndImdbRating, args=(i,)) # 设置每个进程要执行的函数和参数\n",
    "# print('Waiting for all subprocesses done...')\n",
    "# p.close()\n",
    "# p.join()\n",
    "# print('All subprocesses done.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整理code如下\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url_list = \"https://movie.douban.com/\"\n",
    "\n",
    "driver = webdriver.PhantomJS('D:\\\\Github\\\\MovieCrawler\\\\phantomjs.exe')\n",
    "driver.get(url_list)\n",
    "\n",
    "# 把selenium的webdriver调用page_source函数在传入BeautifulSoup中，就可以用BeautifulSoup解析网页了\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "#找豆瓣電影的search bar\n",
    "inputSearch = driver.find_element_by_name(\"search_text\")\n",
    "\n",
    "#這邊輸入你要的中文電影名稱 EX: ChineseMovieName = u\"挖崊老ㄙ\"\n",
    "#ChineseMovieName = u\"天才槍手\"\n",
    "\n",
    "##改成用txt黨輸入要找的電影名稱\n",
    "movieNameList=[]\n",
    "f = open(\"D:\\\\Github\\\\MovieCrawler\\\\MovieNames.txt\",\"r\", encoding = 'UTF-8')\n",
    "for line in f:\n",
    "    movieNameList.append(line[:-1])\n",
    "\n",
    "f.close()\n",
    "\n",
    "ChineseMovieName = movieNameList[4]\n",
    "\n",
    "\n",
    "inputSearch.send_keys(ChineseMovieName)\n",
    "inputSearch.submit()\n",
    "time.sleep(2)\n",
    "\n",
    "#印出找到的電影名稱跟豆瓣評分\n",
    "searchOutput = driver.find_element_by_class_name(\"title\")\n",
    "print(searchOutput.text)\n",
    "searchHerf = searchOutput.find_element_by_css_selector('a').get_attribute('href')\n",
    "print(searchHerf)\n",
    "rating_num = driver.find_element_by_class_name(\"rating_nums\")\n",
    "print(\"豆瓣 : \"+rating_num.text)\n",
    "\n",
    "#點進去該電影後找Imdb的連結\n",
    "driver.get(searchHerf)\n",
    "# get()方法會一直等到頁面被完全加載，然後才會繼續程序, 所以不需要sleep等待\n",
    "#time.sleep(3)\n",
    "html = driver.page_source\n",
    "IMDBLink = driver.find_element_by_partial_link_text(\"tt\").get_attribute('href')\n",
    "#IMDBLink = IMDBLink.find_element_by_css_selector('a').get_attribute('href')\n",
    "#//span[contains(@class, 'pl')]\n",
    "#//a[contains(text(), 'tt')]/@href\n",
    "#//a[contains(@href, 'imdb')]\n",
    "print(IMDBLink)\n",
    "driver.get(IMDBLink)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImdbRating = driver.find_element_by_class_name(\"ratingValue\")\n",
    "print(\"IMDB : \" +ImdbRating.text)\n",
    "movieName = driver.find_element_by_class_name(\"title_wrapper\")\n",
    "print(movieName.text)\n",
    "imdbMovieName = driver.find_element_by_xpath(\"//*[@id='title-overview-widget']//h1\")\n",
    "print(imdbMovieName.text)\n",
    "#//*[@id=\"title-overview-widget\"]/div[2]/div[2]/div/div[2]/div[2]/h1/text()\n",
    "#\"//*[@id='UserContent']//span[@itemprop='description']\"\n",
    "\n",
    "\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因為不知道如何filter掉 h1後方的span, 乾脆用soup把所有span拔掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(soup.find_all('span')) > 0:\n",
    "    soup.span.extract()\n",
    "imdbMovieName2 = soup.find('h1', itemprop=\"name\").getText()\n",
    "print(imdbMovieName2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將得到的英文電影名稱丟到Rotten Tomato裡面查評價"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RottenTomatoURL = \"https://www.rottentomatoes.com/\"\n",
    "RTpage = driver.get(RottenTomatoURL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdbMovieName2)\n",
    "RTsearchURL = \"https://www.rottentomatoes.com/search/?search=\"\n",
    "RTSearch = driver.get(RTsearchURL+imdbMovieName2)\n",
    "# get()方法會一直等到頁面被完全加載，然後才會繼續程序, 所以不需要sleep等待\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = driver.find_element_by_class_name(\"tmeter\")\n",
    "###//span[contains(@class, 'tMeterScore')]\n",
    "print(Score.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
